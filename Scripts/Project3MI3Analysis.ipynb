{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOib+O2766AJwqkqRijZCWE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sabrina-Hendricks/DS4002-Group13-Project3/blob/main/Scripts/Project3MI3Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get photos from Github"
      ],
      "metadata": {
        "id": "rddWqaH8-9lV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dcvh8UUX-2W5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the base URL for your GitHub repository\n",
        "base_url = 'https://raw.githubusercontent.com/Sabrina-Hendricks/DS4002-Group13-Project3/main/Data'\n",
        "\n",
        "# List of breeds (directories)\n",
        "breeds = ['Beagle', 'Boxer', 'Bulldog', 'Chihuahua', 'Chow', 'CockerSpaniel',\n",
        "          'Doberman', 'GermanShepherd', 'Golden', 'GreatDane', 'Husky', 'Lab',\n",
        "          'Pomeranian', 'Pug', 'Rottweiler', 'SaintBernard', 'Shih-tzu', 'StandardPoodle', 'StandardSchnauzer', 'Whippet']  # Add other breeds as needed\n",
        "\n",
        "# Initialize lists to store the image URLs and labels\n",
        "file_urls = []\n",
        "labels = []\n",
        "\n",
        "# Construct URLs for each breed\n",
        "for breed in breeds:\n",
        "    for i in range(1, 101):\n",
        "        file_name = f\"{breed}_{i}.jpg\"  # Assumes file names follow this convention, e.g., 'Beagle_1.jpg'\n",
        "        file_url = f\"{base_url}/{breed}/{file_name}\"\n",
        "\n",
        "        file_urls.append(file_url)\n",
        "        labels.append(breed)\n",
        "\n",
        "# Create a DataFrame with the URLs and labels\n",
        "df = pd.DataFrame({\n",
        "    'file_url': file_urls,\n",
        "    'label': labels\n",
        "})\n",
        "\n",
        "# Display the DataFrame\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prep data generator to get images from urls"
      ],
      "metadata": {
        "id": "l9WMu1S__VHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.utils import Sequence\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Create a mapping from breed labels to integers\n",
        "breed_to_index = {breed: idx for idx, breed in enumerate(df['label'].unique())}\n",
        "df['label_idx'] = df['label'].map(breed_to_index)\n",
        "\n",
        "# Custom data generator to load images in batches from URLs\n",
        "class URLImageDataGenerator(Sequence):\n",
        "    def __init__(self, dataframe, batch_size=32, target_size=(128, 128), shuffle=True):\n",
        "        self.dataframe = dataframe\n",
        "        self.batch_size = batch_size\n",
        "        self.target_size = target_size\n",
        "        self.shuffle = shuffle\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.floor(len(self.dataframe) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        batch_data = self.dataframe.iloc[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "\n",
        "        # Load and preprocess images\n",
        "        X = np.array([load_image_from_url(url, self.target_size) for url in batch_data['file_url']])\n",
        "        y = to_categorical(batch_data['label_idx'].values, num_classes=len(breed_to_index))\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            self.dataframe = self.dataframe.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Initialize the data generator\n",
        "batch_size = 32\n",
        "train_generator = URLImageDataGenerator(df, batch_size=batch_size, target_size=(128, 128))\n"
      ],
      "metadata": {
        "id": "etsNwXlG_CJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define model"
      ],
      "metadata": {
        "id": "Q-ger2AP_cVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Load MobileNetV2 without the top layer\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
        "\n",
        "# Freeze the base model layers to retain pre-trained features\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add new classification layers\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "predictions = Dense(len(breed_to_index), activation='softmax')(x)\n",
        "\n",
        "# Build the model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "XhDCWdcE_dQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train model"
      ],
      "metadata": {
        "id": "l-O0aADF_gCr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "epochs = 10  # Adjust the number of epochs as needed\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=len(train_generator),\n",
        "    epochs=epochs\n",
        ")\n"
      ],
      "metadata": {
        "id": "Vsc0f28d_gnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make predictions"
      ],
      "metadata": {
        "id": "FdVle4Ao_kD0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to make predictions\n",
        "def predict_breed(url):\n",
        "    img_array = np.expand_dims(load_image_from_url(url), axis=0)  # Add batch dimension\n",
        "    prediction = model.predict(img_array)\n",
        "    predicted_index = np.argmax(prediction)\n",
        "    predicted_breed = [breed for breed, idx in breed_to_index.items() if idx == predicted_index][0]\n",
        "    return predicted_breed\n",
        "\n",
        "# Test the prediction\n",
        "test_url = 'https://raw.githubusercontent.com/Sabrina-Hendricks/DS4002-Group13-Project3/main/Data/Beagle/Beagle_1.jpg'\n",
        "print(\"Predicted breed:\", predict_breed(test_url))\n"
      ],
      "metadata": {
        "id": "3pHwYgdj_ktL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}